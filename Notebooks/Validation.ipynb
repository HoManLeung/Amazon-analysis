{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pyspark using Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyspark.ml.classification import LogisticRegression,LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('val').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('val_set.csv', header = True).select('Text', 'verified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                Text|verified|\n",
      "+--------------------+--------+\n",
      "|   really good movie|    true|\n",
      "|review didnt like...|    true|\n",
      "|shabby zombieposs...|    true|\n",
      "|disturbing good a...|    true|\n",
      "|                null|    true|\n",
      "|love plot story l...|    true|\n",
      "|great revenge mov...|    true|\n",
      "|          worth time|    true|\n",
      "|         great movie|    true|\n",
      "|great movie inter...|    true|\n",
      "+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### View data\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Text: 21625\n",
      "Null verified: 0\n"
     ]
    }
   ],
   "source": [
    "#### look for nan values \n",
    "print('Null Text:', df.where((df[\"Text\"].isNull())).count())\n",
    "print('Null verified:', df.where((df[\"verified\"].isNull())).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1729882"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### drop na's\n",
    "df = df.na.drop()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Text|label|\n",
      "+--------------------+-----+\n",
      "|   really good movie|  1.0|\n",
      "|review didnt like...|  1.0|\n",
      "|shabby zombieposs...|  1.0|\n",
      "|disturbing good a...|  1.0|\n",
      "|love plot story l...|  1.0|\n",
      "|great revenge mov...|  1.0|\n",
      "|          worth time|  1.0|\n",
      "|         great movie|  1.0|\n",
      "|great movie inter...|  1.0|\n",
      "|        agreed titty|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### create a Label column\n",
    "df = df.withColumn('label', when(df.verified == 'true', 1.0).otherwise(0.0)).select('Text', 'label')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pipeline & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import pipeline \n",
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "load_pipline = PipelineModel.read().load('pipline_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import model \n",
    "model = LogisticRegressionModel.load('LGmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|                Text|label|          token_text|         rawFeatures|                 idf|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|   really good movie|  1.0|[really, good, mo...|(262144,[0,3,9],[...|(262144,[0,3,9],[...|(262144,[0,3,9],[...|\n",
      "|review didnt like...|  1.0|[review, didnt, l...|(262144,[4,57,59,...|(262144,[4,57,59,...|(262144,[4,57,59,...|\n",
      "|shabby zombieposs...|  1.0|[shabby, zombiepo...|(262144,[0,56,87,...|(262144,[0,56,87,...|(262144,[0,56,87,...|\n",
      "|disturbing good a...|  1.0|[disturbing, good...|(262144,[3,47,114...|(262144,[3,47,114...|(262144,[3,47,114...|\n",
      "|love plot story l...|  1.0|[love, plot, stor...|(262144,[5,7,56,6...|(262144,[5,7,56,6...|(262144,[5,7,56,6...|\n",
      "|great revenge mov...|  1.0|[great, revenge, ...|(262144,[0,2,4,9,...|(262144,[0,2,4,9,...|(262144,[0,2,4,9,...|\n",
      "|          worth time|  1.0|       [worth, time]|(262144,[6,68],[1...|(262144,[6,68],[1...|(262144,[6,68],[1...|\n",
      "|         great movie|  1.0|      [great, movie]|(262144,[0,2],[1....|(262144,[0,2],[0....|(262144,[0,2],[0....|\n",
      "|great movie inter...|  1.0|[great, movie, in...|(262144,[0,2,5,23...|(262144,[0,2,5,23...|(262144,[0,2,5,23...|\n",
      "|        agreed titty|  0.0|     [agreed, titty]|(262144,[4061,346...|(262144,[4061,346...|(262144,[4061,346...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val = load_pipline.transform(df)\n",
    "val.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  1.0|       1.0|[0.16233391170695...|\n",
      "|  1.0|       1.0|[0.17307556783337...|\n",
      "|  1.0|       1.0|[0.20834764398432...|\n",
      "|  1.0|       1.0|[0.17141540031380...|\n",
      "|  1.0|       1.0|[0.17121705636951...|\n",
      "|  1.0|       1.0|[0.20521246079650...|\n",
      "|  1.0|       1.0|[0.16279280651690...|\n",
      "|  1.0|       1.0|[0.15674370187892...|\n",
      "|  1.0|       1.0|[0.20221519088045...|\n",
      "|  0.0|       1.0|[0.16662940387390...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(val)\n",
    "pred.select('label', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.8001095714589961\n"
     ]
    }
   ],
   "source": [
    "#### R0C\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8516355450834219\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "#### Accuracy \n",
    "acc = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "print('Accuracy:', acc.evaluate(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8217072065108203\n"
     ]
    }
   ],
   "source": [
    "#### F1 Score \n",
    "ff = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "print('F1 score:', ff.evaluate(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall , Precision, F1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics as skmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pred.select(['label']).collect()\n",
    "y_pred = pred.select(['prediction']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.25      0.36    294987\n",
      "         1.0       0.86      0.98      0.92   1434895\n",
      "\n",
      "    accuracy                           0.85   1729882\n",
      "   macro avg       0.77      0.61      0.64   1729882\n",
      "weighted avg       0.83      0.85      0.82   1729882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
