{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZT5c-A_a_Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install java libs and spark.\n",
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "! wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "! tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "! pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHESuZi_bRAC",
        "colab_type": "text"
      },
      "source": [
        "### Mount Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v_vGjjsbOlU",
        "colab_type": "code",
        "outputId": "4ff40e4b-dbd8-4e16-e7a6-18b2243993d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyYVNo77bg8X",
        "colab_type": "text"
      },
      "source": [
        "### Install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRKKKLU3bcGH",
        "colab_type": "code",
        "outputId": "545977a1-0d58-4d9f-860f-314a6e21b418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 61kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=a2d10033347b350c913f0cbe12e916dc8f60fd7c1d4a3ab1f5751fa9f129c0f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCNB7ju4cKiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G59EUBfYb8bl",
        "colab_type": "text"
      },
      "source": [
        "### Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPKQNUUZbur3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "APP_NAME = \"EDA1\"\n",
        "SPARK_URL = \"local[*]\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADjhkC-6b0UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Start spark session \n",
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEV5pQxscNFM",
        "colab_type": "text"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV3YRp03cCI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = spark.read.json('/content/drive/My Drive/Movies_and_TV.json.gz').select('overall', 'reviewText', 'summary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIQzStuxcQ_4",
        "colab_type": "code",
        "outputId": "577d0f87-618b-4ee5-d24f-769623fb21b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "### View Data\n",
        "df.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|overall|          reviewText|             summary|\n",
            "+-------+--------------------+--------------------+\n",
            "|    5.0|really happy they...|               great|\n",
            "|    5.0|Having lived in W...|Realistic and Acc...|\n",
            "|    5.0|Excellent look in...|         Peace Child|\n",
            "|    5.0|More than anythin...|Culturally releva...|\n",
            "|    4.0|This is a great m...|Good Movie! Great...|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajAX97xrcZkb",
        "colab_type": "text"
      },
      "source": [
        "### Remove null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYTX-qPrcS8S",
        "colab_type": "code",
        "outputId": "e61bc023-6bf8-437e-85bd-3bb6f4526df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### droping na values \n",
        "df = df.na.drop()\n",
        "df.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8755633"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GlNxg1rdKHV",
        "colab_type": "text"
      },
      "source": [
        "### Remove punctuations & special characters & lowercase words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbUHLuEIc6VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Clean Function \n",
        "def clean_text(c):\n",
        "  c = lower(c)\n",
        "  c = regexp_replace(c, \"^rt \", \"\")\n",
        "  c = regexp_replace(c, \"[\\=.]\",\" \")\n",
        "  c = regexp_replace(c, \"[^a-zA-Z0-9\\\\s]\", \"\")\n",
        "  c = regexp_replace(c, \"  \", \" \")\n",
        "  c = regexp_replace(c, \"   \", \" \")\n",
        "  c = regexp_replace(c, '\\d+', \"\")\n",
        "  return(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klIqEmTmdn4r",
        "colab_type": "code",
        "outputId": "84e73de7-aa4a-413d-d514-3d792c401d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "### View Clean \n",
        "df = df.withColumn(\"clean_text\",clean_text(col('reviewText')))\n",
        "df.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+--------------------+\n",
            "|overall|          reviewText|             summary|          clean_text|\n",
            "+-------+--------------------+--------------------+--------------------+\n",
            "|    5.0|really happy they...|               great|really happy they...|\n",
            "|    5.0|Having lived in W...|Realistic and Acc...|having lived in w...|\n",
            "|    5.0|Excellent look in...|         Peace Child|excellent look in...|\n",
            "|    5.0|More than anythin...|Culturally releva...|more than anythin...|\n",
            "|    4.0|This is a great m...|Good Movie! Great...|this is a great m...|\n",
            "|    5.0|This movie was in...|           Great....|this movie was in...|\n",
            "|    5.0|This is a fascina...|A remarkable true...|this is a fascina...|\n",
            "|    1.0|This DVD appears ...|     Peace Child DVD|this dvd appears ...|\n",
            "|    1.0|This movie is not...|      Not in English|this movie is not...|\n",
            "|    5.0|So sorry I didn't...|            Amazing!|so sorry i didnt ...|\n",
            "|    5.0|Product received ...|A Reunion by Cath...|product received ...|\n",
            "|    5.0|Believe me when I...|Great Gospel VHS ...|believe me when i...|\n",
            "|    5.0|This video arrive...|Reunion The Cathe...|this video arrive...|\n",
            "|    5.0|The Reunion of th...|Reunion - A Video...|the reunion of th...|\n",
            "|    5.0|Wedding Music (3:...|   Track Listings!!!|wedding music  ge...|\n",
            "|    5.0|This is truly a m...|Great video-Super...|this is truly a m...|\n",
            "|    4.0|It is an excellen...|That Billy Zoom S...|it is an excellen...|\n",
            "|    5.0|I have a thing ag...|  Couldn't be better|i have a thing ag...|\n",
            "|    5.0|This DVD is unbel...|   Worth Every Penny|this dvd is unbel...|\n",
            "|    5.0|Just brought this...|X hasn't lost a step|just brought this...|\n",
            "+-------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv7NliTReJF0",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YbsyGkReG10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtilJpfAd1Xp",
        "colab_type": "code",
        "outputId": "dcda3230-af43-49b4-e0a7-5aae4f34a056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "tokenizer = Tokenizer(inputCol=\"clean_text\", outputCol=\"token_text\")\n",
        "token = tokenizer.transform(df).select('overall', 'token_text')\n",
        "token.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+\n",
            "|overall|          token_text|\n",
            "+-------+--------------------+\n",
            "|    5.0|[really, happy, t...|\n",
            "|    5.0|[having, lived, i...|\n",
            "|    5.0|[excellent, look,...|\n",
            "|    5.0|[more, than, anyt...|\n",
            "|    4.0|[this, is, a, gre...|\n",
            "|    5.0|[this, movie, was...|\n",
            "|    5.0|[this, is, a, fas...|\n",
            "|    1.0|[this, dvd, appea...|\n",
            "|    1.0|[this, movie, is,...|\n",
            "|    5.0|[so, sorry, i, di...|\n",
            "|    5.0|[product, receive...|\n",
            "|    5.0|[believe, me, whe...|\n",
            "|    5.0|[this, video, arr...|\n",
            "|    5.0|[the, reunion, of...|\n",
            "|    5.0|[wedding, music, ...|\n",
            "|    5.0|[this, is, truly,...|\n",
            "|    4.0|[it, is, an, exce...|\n",
            "|    5.0|[i, have, a, thin...|\n",
            "|    5.0|[this, dvd, is, u...|\n",
            "|    5.0|[just, brought, t...|\n",
            "+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGxgMkpCfEmD",
        "colab_type": "text"
      },
      "source": [
        "### Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ2Z_sd1evqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avkap2GnfKMB",
        "colab_type": "code",
        "outputId": "de31b286-547f-45b7-9039-654a04d26551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "### remove stops words \n",
        "remover = StopWordsRemover(inputCol='token_text', outputCol='swr_text')\n",
        "swr = remover.transform(token).select('overall','swr_text')\n",
        "swr.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+\n",
            "|overall|            swr_text|\n",
            "+-------+--------------------+\n",
            "|    5.0|[really, happy, g...|\n",
            "|    5.0|[lived, west, new...|\n",
            "|    5.0|[excellent, look,...|\n",
            "|    5.0|[anything, ive, c...|\n",
            "|    4.0|[great, movie, mi...|\n",
            "+-------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSpT7dsPfgxw",
        "colab_type": "text"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJBVp6wyfVMY",
        "colab_type": "code",
        "outputId": "9fbd4ef9-6509-4b17-ad7e-3b228dd84378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUoDSJD3fmeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "# Instantiate stemmer object\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "def stem(in_vec):\n",
        "    out_vec = []\n",
        "    for t in in_vec:\n",
        "        t_stem = stemmer.lemmatize(t)\n",
        "        if len(t_stem) > 2:\n",
        "            out_vec.append(t_stem)       \n",
        "    return(out_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVnxG-c1f1Zs",
        "colab_type": "code",
        "outputId": "93ce0244-e33c-4539-e690-b856dec155f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))\n",
        "\n",
        "# Create new df with vectors containing the stemmed tokens \n",
        "lem_text = swr.withColumn(\"lem_text\", stemmer_udf(col(\"swr_text\"))).select('overall', 'lem_text')\n",
        "lem_text.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+\n",
            "|overall|            lem_text|\n",
            "+-------+--------------------+\n",
            "|    5.0|[really, happy, g...|\n",
            "|    5.0|[lived, west, new...|\n",
            "|    5.0|[excellent, look,...|\n",
            "|    5.0|[anything, ive, c...|\n",
            "|    4.0|[great, movie, mi...|\n",
            "|    5.0|[movie, english, ...|\n",
            "|    5.0|[fascinating, tru...|\n",
            "|    1.0|[dvd, appears, ge...|\n",
            "|    1.0|[movie, english, ...|\n",
            "|    5.0|[sorry, didnt, pu...|\n",
            "|    5.0|[product, receive...|\n",
            "|    5.0|[believe, tell, r...|\n",
            "|    5.0|[video, arrived, ...|\n",
            "|    5.0|[reunion, cathedr...|\n",
            "|    5.0|[wedding, music, ...|\n",
            "|    5.0|[truly, moving, v...|\n",
            "|    4.0|[excellent, exper...|\n",
            "|    5.0|[thing, purchasin...|\n",
            "|    5.0|[dvd, unbelievabl...|\n",
            "|    5.0|[brought, dvd, ho...|\n",
            "+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ4R94l3hi-E",
        "colab_type": "text"
      },
      "source": [
        "### Removing short words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyUqSyo5gOnE",
        "colab_type": "code",
        "outputId": "3a71f073-aa4d-4782-bb56-0919402e367d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "### Removing words \n",
        "filter_length_udf = udf(lambda row: \" \".join([x for x in row if len(x) >= 4]))\n",
        "df2= lem_text.withColumn('words', filter_length_udf(col('lem_text'))).select('overall','words')\n",
        "df2.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+\n",
            "|overall|               words|\n",
            "+-------+--------------------+\n",
            "|    5.0|really happy evan...|\n",
            "|    5.0|lived west guinea...|\n",
            "|    5.0|excellent look co...|\n",
            "|    5.0|anything challeng...|\n",
            "|    4.0|great movie missi...|\n",
            "|    5.0|movie english gre...|\n",
            "|    5.0|fascinating true ...|\n",
            "|    1.0|appears german en...|\n",
            "|    1.0|movie english alt...|\n",
            "|    5.0|sorry didnt purch...|\n",
            "|    5.0|product received ...|\n",
            "|    5.0|believe tell rece...|\n",
            "|    5.0|video arrived per...|\n",
            "|    5.0|reunion cathedral...|\n",
            "|    5.0|wedding music fre...|\n",
            "|    5.0|truly moving vide...|\n",
            "|    4.0|excellent experie...|\n",
            "|    5.0|thing purchasing ...|\n",
            "|    5.0|unbelievable punk...|\n",
            "|    5.0|brought home rock...|\n",
            "+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPI3W_NY0vxd",
        "colab_type": "text"
      },
      "source": [
        "### Export Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TLljjGSh-kP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.write.option(\"header\", \"true\").csv('/content/drive/My Drive/clean_text.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vBr9CuS0tfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}